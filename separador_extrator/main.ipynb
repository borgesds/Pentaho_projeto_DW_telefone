{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Separador e Tratamento de dados para Subir para o BD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BD extrator\n",
    "df_extrator = pd.read_excel('./BD_dados.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_extrator = df_extrator[['Nome_do_Cliente', 'CNPJCPF_do_Cliente', 'Numero_do_auxilio', 'Codigo_da_associacao',     \n",
    "                           'Nome_da_Entidade', 'Data_de_Nascimento', 'Nome_da_Mae', 'Nome_do_Pai', 'Sexo',\n",
    "                           'Numero_do_Documento', 'Orgao_Emissor', 'Estado_do_orgao_Emissor', 'Endereco_de_Correspondencia', 'Bairro',\n",
    "                           'Cidade', 'Estado', 'CEP', 'Naturalidade', 'Nacionalidade', 'email',\n",
    "                           'Codigo_do_Banco_Destinatario_do_Credito',\t'Banco_Destinatario_do_Credito', 'Agencia',\n",
    "                           'Digito_da_Agencia', 'Conta_Corrente',\t'Digito_da_Conta_Corrente', 'Telefone_de_Contato',\n",
    "                           'Celular_1', 'Celular_2']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limpar CPF\n",
    "df_extrator['CNPJCPF_do_Cliente'] = df_extrator['CNPJCPF_do_Cliente'].str.replace('.', '', regex=False)\n",
    "df_extrator['CNPJCPF_do_Cliente'] = df_extrator['CNPJCPF_do_Cliente'].str.replace('-', '', regex=False)\n",
    "\n",
    "# Limpar Documento\n",
    "df_extrator['Numero_do_Documento'] = df_extrator['Numero_do_Documento'].str.replace('.', '', regex=False)\n",
    "df_extrator['Numero_do_Documento'] = df_extrator['Numero_do_Documento'].str.replace('-', '', regex=False)\n",
    "\n",
    "# Limpar CEP\n",
    "df_extrator['CEP'] = df_extrator['CEP'].str.replace('.', '', regex=False)\n",
    "df_extrator['CEP'] = df_extrator['CEP'].str.replace('-', '', regex=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tratar telefones da coluna Telefone_de_Contato\n",
    "\n",
    "mask_parenteses = df_extrator['Telefone_de_Contato'].str.contains(r'\\(.*\\)', na=False)\n",
    "mask_espaco = df_extrator['Telefone_de_Contato'].str.contains(r'\\s', na=False)\n",
    "\n",
    "# Inicializar as colunas 'ddd2' e 'Telefone2' com valores vazios\n",
    "df_extrator['ddd1'] = ''\n",
    "df_extrator['Telefone1'] = ''\n",
    "\n",
    "# Extrair DDD e telefone dos casos com parênteses\n",
    "df_extrator.loc[mask_parenteses, 'ddd1'] = df_extrator.loc[mask_parenteses, 'Telefone_de_Contato'].str.extract(r'\\((\\d+)\\)', expand=False)\n",
    "df_extrator.loc[mask_parenteses, 'Telefone1'] = df_extrator.loc[mask_parenteses, 'Telefone_de_Contato'].str.extract(r'\\)\\s*(\\d+)', expand=False)\n",
    "\n",
    "# Extrair DDD e telefone dos casos com espaço\n",
    "df_espaco = df_extrator.loc[~mask_parenteses & mask_espaco, 'Telefone_de_Contato'].str.split(' ', n=1, expand=True)\n",
    "if not df_espaco.empty:\n",
    "    df_extrator.loc[~mask_parenteses & mask_espaco, 'ddd1'] = df_espaco[0]\n",
    "    df_extrator.loc[~mask_parenteses & mask_espaco, 'Telefone1'] = df_espaco[1]\n",
    "\n",
    "df_extrator['ddd1'] = df_extrator['ddd1'].astype(str)\n",
    "df_extrator['Telefone1'] = df_extrator['Telefone1'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tratar telefones da coluna Celular_1\n",
    "\n",
    "# Verificar se há parênteses e espaço na coluna 'Celular_1'\n",
    "mask_parenteses = df_extrator['Celular_1'].str.contains(r'\\(.*\\)', na=False)\n",
    "mask_espaco = df_extrator['Celular_1'].str.contains(r'\\s', na=False)\n",
    "\n",
    "# Inicializar as colunas 'ddd2' e 'Telefone2' com valores vazios\n",
    "df_extrator['ddd2'] = ''\n",
    "df_extrator['Telefone2'] = ''\n",
    "\n",
    "# Extrair DDD e telefone dos casos com parênteses\n",
    "df_extrator.loc[mask_parenteses, 'ddd2'] = df_extrator.loc[mask_parenteses, 'Celular_1'].str.extract(r'\\((\\d+)\\)', expand=False)\n",
    "df_extrator.loc[mask_parenteses, 'Telefone2'] = df_extrator.loc[mask_parenteses, 'Celular_1'].str.extract(r'\\)\\s*(\\d+)', expand=False)\n",
    "\n",
    "# Extrair DDD e telefone dos casos com espaço\n",
    "df_espaco = df_extrator.loc[~mask_parenteses & mask_espaco, 'Celular_1'].str.split(' ', n=1, expand=True)\n",
    "if not df_espaco.empty:\n",
    "    df_extrator.loc[~mask_parenteses & mask_espaco, 'ddd2'] = df_espaco[0]\n",
    "    df_extrator.loc[~mask_parenteses & mask_espaco, 'Telefone2'] = df_espaco[1]\n",
    "\n",
    "df_extrator['ddd2'] = df_extrator['ddd2'].astype(str)\n",
    "df_extrator['Telefone2'] = df_extrator['Telefone2'].astype(str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tratar telefones da coluna Celular_2\n",
    "\n",
    "# Verificar se há parênteses e espaço na coluna 'Celular_2'\n",
    "mask_parenteses = df_extrator['Celular_2'].str.contains(r'\\(.*\\)', na=False)\n",
    "mask_espaco = df_extrator['Celular_2'].str.contains(r'\\s', na=False)\n",
    "\n",
    "# Inicializar as colunas 'ddd2' e 'Telefone2' com valores vazios\n",
    "df_extrator['ddd3'] = ''\n",
    "df_extrator['Telefone3'] = ''\n",
    "\n",
    "# Extrair DDD e telefone dos casos com parênteses\n",
    "df_extrator.loc[mask_parenteses, 'ddd3'] = df_extrator.loc[mask_parenteses, 'Celular_2'].str.extract(r'\\((\\d+)\\)', expand=False)\n",
    "df_extrator.loc[mask_parenteses, 'Telefone3'] = df_extrator.loc[mask_parenteses, 'Celular_2'].str.extract(r'\\)\\s*(\\d+)', expand=False)\n",
    "\n",
    "# Extrair DDD e telefone dos casos com espaço\n",
    "df_espaco = df_extrator.loc[~mask_parenteses & mask_espaco, 'Celular_2'].str.split(' ', n=1, expand=True)\n",
    "if not df_espaco.empty:\n",
    "    df_extrator.loc[~mask_parenteses & mask_espaco, 'ddd3'] = df_espaco[0]\n",
    "    df_extrator.loc[~mask_parenteses & mask_espaco, 'Telefone3'] = df_espaco[1]\n",
    "\n",
    "df_extrator['ddd3'] = df_extrator['ddd3'].astype(str)\n",
    "df_extrator['Telefone3'] = df_extrator['Telefone3'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_extrator = df_extrator[['Nome_do_Cliente', 'CNPJCPF_do_Cliente', 'Numero_do_auxilio', 'Codigo_da_associacao',     \n",
    "                           'Nome_da_Entidade', 'Data_de_Nascimento', 'Nome_da_Mae', 'Nome_do_Pai', 'Sexo',\n",
    "                           'Numero_do_Documento', 'Orgao_Emissor', 'Estado_do_orgao_Emissor', 'Endereco_de_Correspondencia', 'Bairro',\n",
    "                           'Cidade', 'Estado', 'CEP', 'Naturalidade', 'Nacionalidade', 'email',\n",
    "                           'Codigo_do_Banco_Destinatario_do_Credito',\t'Banco_Destinatario_do_Credito', 'Agencia',\n",
    "                           'Digito_da_Agencia', 'Conta_Corrente', 'Digito_da_Conta_Corrente', 'ddd1', 'Telefone1', 'ddd2', 'Telefone2', 'ddd3', 'Telefone3']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_extrator['Digito_da_Agencia'] = df_extrator['Digito_da_Agencia'].fillna('0').replace('', '0')\n",
    "df_extrator['Digito_da_Agencia'] = pd.to_numeric(df_extrator['Digito_da_Agencia'], errors='coerce').fillna(0).astype('int64')\n",
    "df_extrator['CEP'] = df_extrator['CEP'].fillna(0).astype('int64')\n",
    "df_extrator['CNPJCPF_do_Cliente'] = df_extrator['CNPJCPF_do_Cliente'].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colunas_numericas = ['CNPJCPF_do_Cliente', 'Numero_do_auxilio', 'CEP',\n",
    "                     'Codigo_do_Banco_Destinatario_do_Credito', 'Agencia',\n",
    "                     'Digito_da_Agencia', 'Conta_Corrente', 'Digito_da_Conta_Corrente']\n",
    "\n",
    "# Loop pelas colunas numéricas\n",
    "for coluna in colunas_numericas:\n",
    "    df_extrator[coluna] = df_extrator[coluna].replace(r'\\D', '', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# desmontar formato cientifico\n",
    "df_extrator['Numero_do_auxilio'] = df_extrator['Numero_do_auxilio'].apply(lambda x: format(x, '.0f'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_extrator.shape)\n",
    "df_extrator.drop_duplicates(inplace=True)\n",
    "print(df_extrator.shape)\n",
    "\n",
    "# Alinha dataframe\n",
    "df_extrator = df_extrator.sort_values('CNPJCPF_do_Cliente')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_extrator.to_excel('Base_tratada.xlsx', index=False)\n",
    "print('BD  TRATADO!!!')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tratamento para o Data Warehouse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Tabela dim_cliente\n",
    "dim_cliente = df_extrator[['Nome_do_Cliente', 'CNPJCPF_do_Cliente',\n",
    "                           'Data_de_Nascimento', 'Nome_da_Mae', 'Nome_do_Pai',\n",
    "                           'Sexo', 'Numero_do_Documento', 'Orgao_Emissor', 'Estado_do_orgao_Emissor',\n",
    "                           'Naturalidade', 'Nacionalidade', 'email']]\n",
    "\n",
    "# Tabela dim_entidade\n",
    "dim_entidade = df_extrator[['CNPJCPF_do_Cliente', 'Codigo_da_associacao']]\n",
    "\n",
    "# Tabela beneficio\n",
    "dim_beneficio = df_extrator[['CNPJCPF_do_Cliente', 'Numero_do_auxilio']]\n",
    "\n",
    "# Tabela dim_endreco\n",
    "dim_endereco = df_extrator[['CNPJCPF_do_Cliente', 'Endereco_de_Correspondencia',\n",
    "                            'Bairro', 'Cidade', 'Estado', 'CEP']]\n",
    "\n",
    "# Tabela dim_banco\n",
    "dim_banco = df_extrator[['CNPJCPF_do_Cliente', 'Codigo_do_Banco_Destinatario_do_Credito',\n",
    "                         'Banco_Destinatario_do_Credito', 'Agencia', 'Digito_da_Agencia',\n",
    "                         'Conta_Corrente',\t'Digito_da_Conta_Corrente']]\n",
    "\n",
    "fato_tefone = df_extrator[['CNPJCPF_do_Cliente', 'ddd1', 'Telefone1', 'ddd2', 'Telefone2', 'ddd3', 'Telefone3']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dim_cliente\n",
    "qtd_dc = dim_cliente.shape[0]\n",
    "\n",
    "dim_cliente = dim_cliente.copy()\n",
    "dim_cliente.drop_duplicates(subset='CNPJCPF_do_Cliente', inplace=True)\n",
    "\n",
    "print(f'Quantidade de linhas dim_cliente antes {qtd_dc} depois {dim_cliente.shape[0]}\\n')\n",
    "\n",
    "# dim_entidade\n",
    "qtd_de = dim_entidade.shape[0]\n",
    "\n",
    "dim_entidade = dim_entidade.copy()\n",
    "dim_entidade.drop_duplicates(inplace=True)\n",
    "\n",
    "print(f'Quantidade de linhas dim_entidade antes {qtd_de} depois {dim_entidade.shape[0]}\\n')\n",
    "\n",
    "# dim_beneficio\n",
    "qtd_db = dim_beneficio.shape[0]\n",
    "\n",
    "dim_beneficio = dim_beneficio.copy()\n",
    "dim_beneficio.drop_duplicates(inplace=True)\n",
    "\n",
    "print(f'Quantidade de linhas dim_beneficio antes {qtd_db} depois {dim_beneficio.shape[0]}\\n')\n",
    "\n",
    "# dim_endereco\n",
    "qtd_den = dim_endereco.shape[0]\n",
    "\n",
    "dim_endereco = dim_endereco.copy()\n",
    "dim_endereco.drop_duplicates(inplace=True)\n",
    "\n",
    "print(f'Quantidade de linhas dim_endereco antes {qtd_den} depois {dim_endereco.shape[0]}\\n')\n",
    "\n",
    "# dim_banco\n",
    "qtd_dban = dim_banco.shape[0]\n",
    "\n",
    "dim_banco = dim_banco.copy()\n",
    "dim_banco.drop_duplicates(inplace=True)\n",
    "\n",
    "print(f'Quantidade de linhas dim_endereco antes {qtd_dban} depois {dim_banco.shape[0]}\\n')\n",
    "\n",
    "# fato_tefone\n",
    "qtd_ft = fato_tefone.shape[0]\n",
    "\n",
    "fato_tefone = fato_tefone.copy()\n",
    "fato_tefone.drop_duplicates(inplace=True)\n",
    "\n",
    "print(f'Quantidade de linhas fato_tefone antes {qtd_ft} depois {fato_tefone.shape[0]}\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dim_cliente\n",
    "\n",
    "# salvar arquivo\n",
    "dim_cliente.to_csv('dim_cliente_final.csv', sep=';', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dim_entidade\n",
    "\n",
    "# Encontrar os duplicados\n",
    "cpfs_duplicados_entidade = dim_entidade[\n",
    "    dim_entidade['CNPJCPF_do_Cliente'].duplicated(keep=False)]['CNPJCPF_do_Cliente'].unique()\n",
    "\n",
    "# separando os duplicados\n",
    "df_dup_entidade = dim_entidade[dim_entidade['CNPJCPF_do_Cliente'].isin(cpfs_duplicados_entidade)].copy()\n",
    "\n",
    "# Separa os CPFs não duplicados em um novo DataFrame\n",
    "df_nao_dup_entidade = dim_entidade[~dim_entidade['CNPJCPF_do_Cliente'].isin(cpfs_duplicados_entidade)].copy()\n",
    "\n",
    "# Cria um dicionário para armazenar os dados dos CPFs duplicados\n",
    "dados_dup_entidade = {}\n",
    "\n",
    "# Percorre o DataFrame dos CPFs duplicados\n",
    "for index, row in df_dup_entidade.iterrows():\n",
    "    cpf = row['CNPJCPF_do_Cliente']\n",
    "    \n",
    "    # Verifica se o CPF já está presente no dicionário\n",
    "    if cpf in dados_dup_entidade:\n",
    "        # Adiciona os dados às colunas à frente do primeiro CPF duplicado encontrado\n",
    "        for i, col in enumerate(row.index[1:], start=2):\n",
    "            dados_dup_entidade[cpf].append(row[col])\n",
    "    else:\n",
    "        # Cria uma nova entrada no dicionário para o CPF\n",
    "        dados_dup_entidade[cpf] = list(row[1:])\n",
    "\n",
    "# Converte o dicionário em DataFrame\n",
    "dim_entidade = pd.DataFrame.from_dict(dados_dup_entidade, orient='index')\n",
    "\n",
    "# Reseta o índice e move para a primeira coluna\n",
    "dim_entidade = dim_entidade.reset_index().rename(columns={'index': 'cpf'})\n",
    "\n",
    "# Adiciona a coluna \"cpf\" ao início do DataFrame\n",
    "dim_entidade.insert(0, 'cpf', dim_entidade.pop('cpf'))\n",
    "\n",
    "# Renomear colunas\n",
    "nome_colunas = {'CNPJCPF_do_Cliente': 'cpf', 'Codigo_da_associacao': 0}\n",
    "df_nao_dup_entidade = df_nao_dup_entidade.rename(columns=nome_colunas)\n",
    "\n",
    "# Concatenar os DataFrames verticalmente\n",
    "dim_entidade_final = pd.concat([dim_entidade, df_nao_dup_entidade], axis=0)\n",
    "\n",
    "dim_entidade_final = dim_entidade_final.reset_index(drop='index')\n",
    "\n",
    "# salvar arquivo\n",
    "dim_entidade_final.to_csv('dim_entidade_final.csv', sep=';', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dim_beneficio\n",
    "\n",
    "cpfs_duplicados_beneficio = dim_beneficio[\n",
    "    dim_beneficio['CNPJCPF_do_Cliente'].duplicated(keep=False)]['CNPJCPF_do_Cliente'].unique()\n",
    "\n",
    "# separar os duplicados\n",
    "df_dup_beneficio = dim_beneficio[dim_beneficio['CNPJCPF_do_Cliente'].isin(cpfs_duplicados_beneficio)].copy()\n",
    "\n",
    "# não duplicados\n",
    "df_nao_dup_beneficio = dim_beneficio[~dim_beneficio['CNPJCPF_do_Cliente'].isin(cpfs_duplicados_beneficio)].copy()\n",
    "\n",
    "dados_dup_beneficio = {}\n",
    "\n",
    "for index, row in df_dup_beneficio.iterrows():\n",
    "    cpf1 = row['CNPJCPF_do_Cliente']\n",
    "    \n",
    "    if cpf1 in dados_dup_beneficio:\n",
    "        for i, col in enumerate(row.index[1:], start=2):\n",
    "            dados_dup_beneficio[cpf1].append(row[col])\n",
    "        \n",
    "    else:\n",
    "        dados_dup_beneficio[cpf1] = list(row[1:])\n",
    "\n",
    "# converter o dicionario em Dataframe\n",
    "dim_beneficio = pd.DataFrame.from_dict(dados_dup_beneficio, orient='index')\n",
    "\n",
    "dim_beneficio = dim_beneficio.reset_index().rename(columns={'index': 'cpf'})\n",
    "\n",
    "dim_beneficio.insert(0, 'cpf', dim_beneficio.pop('cpf'))\n",
    "\n",
    "# Renomear colunas não dplicadas\n",
    "nome_colunas = {'CNPJCPF_do_Cliente': 'cpf', 'Numero_do_auxilio': 0}\n",
    "df_nao_dup_beneficio = df_nao_dup_beneficio.rename(columns=nome_colunas)\n",
    "\n",
    "# Concatenar os DataFrames verticalmente\n",
    "dim_beneficio_final = pd.concat([dim_beneficio, df_nao_dup_beneficio], axis=0)\n",
    "\n",
    "dim_beneficio_final = dim_beneficio_final.reset_index(drop='index')\n",
    "\n",
    "# salvar arquivo\n",
    "dim_beneficio_final.to_csv('dim_beneficio_final.csv', sep=';', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dim_endereco\n",
    "\n",
    "dim_endereco.drop_duplicates(subset='CNPJCPF_do_Cliente', inplace=True)\n",
    "\n",
    "# salvar arquivo\n",
    "dim_endereco.to_csv('dim_endereco_final.csv', sep=';', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dim_banco\n",
    "\n",
    "dim_banco.drop_duplicates(subset='CNPJCPF_do_Cliente', inplace=True)\n",
    "\n",
    "# salvar arquivo\n",
    "dim_banco.to_csv('dim_banco_final.csv', sep=';', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fato_tefone\n",
    "\n",
    "fato_tefone.drop_duplicates(subset='CNPJCPF_do_Cliente', inplace=True)\n",
    "\n",
    "# salvar arquivo\n",
    "fato_tefone.to_csv('fato_tefonefinal.csv', sep=';', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
